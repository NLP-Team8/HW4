{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (2.3.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (2.0.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (4.37.2)\n",
            "Requirement already satisfied: numpy in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (1.24.3)\n",
            "Requirement already satisfied: requests in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (2.32.2)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (4.66.4)\n",
            "Requirement already satisfied: matplotlib in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (3.7.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from bert_score) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from pandas>=1.0.1->bert_score) (2023.3)\n",
            "Requirement already satisfied: filelock in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (4.11.0)\n",
            "Requirement already satisfied: sympy in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: networkx in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (3.1)\n",
            "Requirement already satisfied: jinja2 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from torch>=1.0.0->bert_score) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score) (12.5.82)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (0.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (2023.10.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from transformers>=3.0.0->bert_score) (0.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (10.3.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from matplotlib->bert_score) (6.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from requests->bert_score) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from requests->bert_score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from requests->bert_score) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from requests->bert_score) (2024.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->bert_score) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m289.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_Vn6_idrp5GB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k9Yjxl17p5GC"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"preprocessed_data/train.csv\")\n",
        "df_test = pd.read_csv(\"preprocessed_data/test.csv\")\n",
        "df_val = pd.read_csv(\"preprocessed_data/val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "No5eKD5Np5GC"
      },
      "outputs": [],
      "source": [
        "def prepare_data(df):\n",
        "    df['text'] = df['transcription'] + \" [SEP] \" + df['description']\n",
        "    return df['text'].tolist()\n",
        "\n",
        "train_texts = prepare_data(df_train)\n",
        "val_texts = prepare_data(df_val)\n",
        "test_texts = prepare_data(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjAD1pHxp5GD",
        "outputId": "8097d7cc-222e-45f1-96c2-ef09e1cd9287"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pad token set to: <|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Verify that the pad token is set correctly\n",
        "print(\"Pad token set to:\", tokenizer.pad_token)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=\"longest\", max_length=512)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=\"longest\", max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z7HrUAFLp5GD"
      },
      "outputs": [],
      "source": [
        "class Medical_dataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return input_ids as labels for model training\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = item['input_ids'].clone()\n",
        "        return item\n",
        "\n",
        "train_dataset = Medical_dataset(train_encodings)\n",
        "val_dataset = Medical_dataset(val_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_before = GPT2LMHeadModel.from_pretrained('FinancialSupport/gpt2-ft-medical-qa')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_before.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMcTUKX6p5GD",
        "outputId": "fd031e44-85f1-40b7-9d9b-601223af0d1e"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('FinancialSupport/gpt2-ft-medical-qa')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "O9AAAASIq17Z",
        "outputId": "24fa3ef3-4ee7-48eb-f270-76827760c611"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f91def1abd2442588a124cd11f90d664",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f51fc342bcdf418b97281a6acdec948b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bbd55d2f8d84400bac6efd49949bb06",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e19d4f8098c84ee4a5985404c9737764",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e360f158138e4818a696f711c5c1f8e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddd163654b94b45bbc249ed4725a79a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                       transcription  \\\n",
            "0  history of present illness:  ,the patient is a...   \n",
            "1  hx: ,this 46y/o rhm with htn was well until 2 ...   \n",
            "2  title of operation: , placement of right new v...   \n",
            "\n",
            "                                         description  \\\n",
            "0   a woman presenting to our clinic for the firs...   \n",
            "1   patient with sudden onset dizziness and rue c...   \n",
            "2   placement of right new ventriculoperitoneal (...   \n",
            "\n",
            "                               generated_description    bleu_1    bleu_2  \\\n",
            "0  history of present illness: ,the patient is a ...  0.050000  0.048663   \n",
            "1  hx:,this 46y/o rhm with htn was well until 2 w...  0.011852  0.009377   \n",
            "2  title of operation:, placement of right new ve...  0.021592  0.020921   \n",
            "\n",
            "     bleu_3    bleu_4   rouge_1   rouge_2   rouge_L  bert_precision  \\\n",
            "0  0.048775  0.045940  0.093434  0.088608  0.093434       -0.293104   \n",
            "1  0.008453  0.006950  0.027064  0.016282  0.024357       -0.436072   \n",
            "2  0.021045  0.019549  0.044213  0.041721  0.044213       -0.420951   \n",
            "\n",
            "   bert_recall   bert_f1  \n",
            "0     0.649872  0.136335  \n",
            "1     0.311689 -0.089089  \n",
            "2     0.526918  0.009585  \n",
            "Average BLEU-1 score: 0.027814764832308696\n",
            "Average BLEU-2 score: 0.026320113863428234\n",
            "Average BLEU-3 score: 0.026091040771012337\n",
            "Average BLEU-4 score: 0.024146234789758\n",
            "Average ROUGE-1 score: 0.0549037356240884\n",
            "Average ROUGE-2 score: 0.048870270349230416\n",
            "Average ROUGE-L score: 0.0540016156421308\n",
            "Average BERT Precision: -0.38337549567222595\n",
            "Average BERT Recall: 0.4961597224076589\n",
            "Average BERT F1: 0.01894348921875159\n"
          ]
        }
      ],
      "source": [
        "def generate_description(transcription):\n",
        "    input_text = transcription\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "    # Check if input_ids exceed the model's vocab size\n",
        "    if torch.max(input_ids) >= tokenizer.vocab_size:\n",
        "        raise ValueError(\"Input IDs contain indices outside the model's vocabulary size.\")\n",
        "    \n",
        "    # Add attention mask creation\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)\n",
        "\n",
        "    # Adjust max_length if necessary\n",
        "    max_length = min(4096, model_before.config.n_positions)\n",
        "\n",
        "    output = model_before.generate(input_ids, attention_mask=attention_mask, max_length=max_length, num_return_sequences=1)\n",
        "    description = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    description = description.split(\"[SEP]\")[-1].strip()\n",
        "    return description\n",
        "\n",
        "# Select the first 3 rows of the validation set\n",
        "df_val_sample = df_val.head(3).copy()\n",
        "\n",
        "# Generate descriptions for the first 3 rows of the validation set\n",
        "df_val_sample['generated_description'] = df_val_sample['transcription'].apply(generate_description)\n",
        "\n",
        "# Calculate BLEU scores\n",
        "def calculate_bleu_scores(reference, candidate):\n",
        "    reference = [reference.split()]\n",
        "    candidate = candidate.split()\n",
        "    smoothing_function = SmoothingFunction().method1\n",
        "    bleu_1 = sentence_bleu(reference, candidate, weights=(1.0, 0.0, 0.0, 0.0), smoothing_function=smoothing_function)\n",
        "    bleu_2 = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0.0, 0.0), smoothing_function=smoothing_function)\n",
        "    bleu_3 = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0.0), smoothing_function=smoothing_function)\n",
        "    bleu_4 = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)\n",
        "    return bleu_1, bleu_2, bleu_3, bleu_4\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "def calculate_rouge(reference, candidate):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, candidate)\n",
        "    return scores['rouge1'].fmeasure, scores['rouge2'].fmeasure, scores['rougeL'].fmeasure\n",
        "\n",
        "# Calculate BERTScore\n",
        "def calculate_bertscore(reference, candidate):\n",
        "    P, R, F1 = bert_score([candidate], [reference], lang='en', rescale_with_baseline=True)\n",
        "    return P.mean().item(), R.mean().item(), F1.mean().item()\n",
        "\n",
        "# Apply all calculations\n",
        "df_val_sample[['bleu_1', 'bleu_2', 'bleu_3', 'bleu_4']] = df_val_sample.apply(\n",
        "    lambda row: calculate_bleu_scores(row['description'], row['generated_description']),\n",
        "    axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "df_val_sample[['rouge_1', 'rouge_2', 'rouge_L']] = df_val_sample.apply(\n",
        "    lambda row: calculate_rouge(row['description'], row['generated_description']),\n",
        "    axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "df_val_sample[['bert_precision', 'bert_recall', 'bert_f1']] = df_val_sample.apply(\n",
        "    lambda row: calculate_bertscore(row['description'], row['generated_description']),\n",
        "    axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "# Print the scores for the first 3 rows\n",
        "print(df_val_sample[['transcription', 'description', 'generated_description', 'bleu_1', 'bleu_2', 'bleu_3', 'bleu_4', 'rouge_1', 'rouge_2', 'rouge_L', 'bert_precision', 'bert_recall', 'bert_f1']])\n",
        "\n",
        "# Print the average scores for the first 3 rows\n",
        "average_bleu_1 = df_val_sample['bleu_1'].mean()\n",
        "average_bleu_2 = df_val_sample['bleu_2'].mean()\n",
        "average_bleu_3 = df_val_sample['bleu_3'].mean()\n",
        "average_bleu_4 = df_val_sample['bleu_4'].mean()\n",
        "average_rouge_1 = df_val_sample['rouge_1'].mean()\n",
        "average_rouge_2 = df_val_sample['rouge_2'].mean()\n",
        "average_rouge_L = df_val_sample['rouge_L'].mean()\n",
        "average_bert_precision = df_val_sample['bert_precision'].mean()\n",
        "average_bert_recall = df_val_sample['bert_recall'].mean()\n",
        "average_bert_f1 = df_val_sample['bert_f1'].mean()\n",
        "\n",
        "print(f\"Average BLEU-1 score: {average_bleu_1}\")\n",
        "print(f\"Average BLEU-2 score: {average_bleu_2}\")\n",
        "print(f\"Average BLEU-3 score: {average_bleu_3}\")\n",
        "print(f\"Average BLEU-4 score: {average_bleu_4}\")\n",
        "print(f\"Average ROUGE-1 score: {average_rouge_1}\")\n",
        "print(f\"Average ROUGE-2 score: {average_rouge_2}\")\n",
        "print(f\"Average ROUGE-L score: {average_rouge_L}\")\n",
        "print(f\"Average BERT Precision: {average_bert_precision}\")\n",
        "print(f\"Average BERT Recall: {average_bert_recall}\")\n",
        "print(f\"Average BERT F1: {average_bert_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/accelerate/accelerator.py:451: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # number of training epochs\n",
        "    per_device_train_batch_size=2,   # batch size for training\n",
        "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    evaluation_strategy=\"epoch\",     # evaluate each epoch\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1491' max='1491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1491/1491 15:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.134238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.771300</td>\n",
              "      <td>1.954901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.129300</td>\n",
              "      <td>1.912344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1491, training_loss=2.3001555066073522, metrics={'train_runtime': 909.5495, 'train_samples_per_second': 13.101, 'train_steps_per_second': 1.639, 'total_flos': 3113555853312000.0, 'train_loss': 2.3001555066073522, 'epoch': 3.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/local/aabavandpour/anaconda3/envs/Alireza/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                       transcription  \\\n",
            "0  history of present illness:  ,the patient is a...   \n",
            "1  hx: ,this 46y/o rhm with htn was well until 2 ...   \n",
            "2  title of operation: , placement of right new v...   \n",
            "\n",
            "                                         description  \\\n",
            "0   a woman presenting to our clinic for the firs...   \n",
            "1   patient with sudden onset dizziness and rue c...   \n",
            "2   placement of right new ventriculoperitoneal (...   \n",
            "\n",
            "                               generated_description    bleu_1    bleu_2  \\\n",
            "0  history of present illness: ,the patient is a ...  0.048942  0.047632   \n",
            "1  hx:,this 46y/o rhm with htn was well until 2 w...  0.010710  0.008472   \n",
            "2  placement of right new ventriculoperitoneal (v...  1.000000  1.000000   \n",
            "\n",
            "     bleu_3    bleu_4   rouge_1   rouge_2   rouge_L  bert_precision  \\\n",
            "0  0.047752  0.044965  0.091584  0.086849  0.091584       -0.293104   \n",
            "1  0.007644  0.006279  0.022699  0.012642  0.022699       -0.436072   \n",
            "2  1.000000  1.000000  1.000000  1.000000  1.000000        1.000000   \n",
            "\n",
            "   bert_recall   bert_f1  \n",
            "0     0.649872  0.136335  \n",
            "1     0.311689 -0.089089  \n",
            "2     1.000000  1.000000  \n",
            "Average BLEU-1 score: 0.3532171012090691\n",
            "Average BLEU-2 score: 0.3520348217813433\n",
            "Average BLEU-3 score: 0.3517988230535507\n",
            "Average BLEU-4 score: 0.3504146379791368\n",
            "Average ROUGE-1 score: 0.37142759042612966\n",
            "Average ROUGE-2 score: 0.36649695342244587\n",
            "Average ROUGE-L score: 0.37142759042612966\n",
            "Average BERT Precision: 0.09027474125226338\n",
            "Average BERT Recall: 0.6538538237412771\n",
            "Average BERT F1: 0.3490818838278453\n"
          ]
        }
      ],
      "source": [
        "def generate_description(transcription):\n",
        "    input_text = transcription\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "    # Check if input_ids exceed the model's vocab size\n",
        "    if torch.max(input_ids) >= tokenizer.vocab_size:\n",
        "        raise ValueError(\"Input IDs contain indices outside the model's vocabulary size.\")\n",
        "    \n",
        "    # Add attention mask creation\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)\n",
        "\n",
        "    # Adjust max_length if necessary\n",
        "    max_length = min(4096, model.config.n_positions)\n",
        "\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=max_length, num_return_sequences=1)\n",
        "    description = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    description = description.split(\"[SEP]\")[-1].strip()\n",
        "    return description\n",
        "\n",
        "# Select the first 3 rows of the validation set\n",
        "df_val_sample = df_val.head(3).copy()\n",
        "\n",
        "# Generate descriptions for the first 3 rows of the validation set\n",
        "df_val_sample['generated_description'] = df_val_sample['transcription'].apply(generate_description)\n",
        "\n",
        "# Calculate BLEU scores\n",
        "def calculate_bleu_scores(reference, candidate):\n",
        "    reference = [reference.split()]\n",
        "    candidate = candidate.split()\n",
        "    smoothing_function = SmoothingFunction().method1\n",
        "    bleu_1 = sentence_bleu(reference, candidate, weights=(1.0, 0.0, 0.0, 0.0), smoothing_function=smoothing_function)\n",
        "    bleu_2 = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0.0, 0.0), smoothing_function=smoothing_function)\n",
        "    bleu_3 = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0.0), smoothing_function=smoothing_function)\n",
        "    bleu_4 = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)\n",
        "    return bleu_1, bleu_2, bleu_3, bleu_4\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "def calculate_rouge(reference, candidate):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference, candidate)\n",
        "    return scores['rouge1'].fmeasure, scores['rouge2'].fmeasure, scores['rougeL'].fmeasure\n",
        "\n",
        "# Calculate BERTScore\n",
        "def calculate_bertscore(reference, candidate):\n",
        "    P, R, F1 = bert_score([candidate], [reference], lang='en', rescale_with_baseline=True)\n",
        "    return P.mean().item(), R.mean().item(), F1.mean().item()\n",
        "\n",
        "# Apply all calculations\n",
        "df_val_sample[['bleu_1', 'bleu_2', 'bleu_3', 'bleu_4']] = df_val_sample.apply(\n",
        "    lambda row: calculate_bleu_scores(row['description'], row['generated_description']),\n",
        "    axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "df_val_sample[['rouge_1', 'rouge_2', 'rouge_L']] = df_val_sample.apply(\n",
        "    lambda row: calculate_rouge(row['description'], row['generated_description']),\n",
        "    axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "df_val_sample[['bert_precision', 'bert_recall', 'bert_f1']] = df_val_sample.apply(\n",
        "    lambda row: calculate_bertscore(row['description'], row['generated_description']),\n",
        "    axis=1, result_type='expand'\n",
        ")\n",
        "\n",
        "# Print the scores for the first 3 rows\n",
        "print(df_val_sample[['transcription', 'description', 'generated_description', 'bleu_1', 'bleu_2', 'bleu_3', 'bleu_4', 'rouge_1', 'rouge_2', 'rouge_L', 'bert_precision', 'bert_recall', 'bert_f1']])\n",
        "\n",
        "# Print the average scores for the first 3 rows\n",
        "average_bleu_1 = df_val_sample['bleu_1'].mean()\n",
        "average_bleu_2 = df_val_sample['bleu_2'].mean()\n",
        "average_bleu_3 = df_val_sample['bleu_3'].mean()\n",
        "average_bleu_4 = df_val_sample['bleu_4'].mean()\n",
        "average_rouge_1 = df_val_sample['rouge_1'].mean()\n",
        "average_rouge_2 = df_val_sample['rouge_2'].mean()\n",
        "average_rouge_L = df_val_sample['rouge_L'].mean()\n",
        "average_bert_precision = df_val_sample['bert_precision'].mean()\n",
        "average_bert_recall = df_val_sample['bert_recall'].mean()\n",
        "average_bert_f1 = df_val_sample['bert_f1'].mean()\n",
        "\n",
        "print(f\"Average BLEU-1 score: {average_bleu_1}\")\n",
        "print(f\"Average BLEU-2 score: {average_bleu_2}\")\n",
        "print(f\"Average BLEU-3 score: {average_bleu_3}\")\n",
        "print(f\"Average BLEU-4 score: {average_bleu_4}\")\n",
        "print(f\"Average ROUGE-1 score: {average_rouge_1}\")\n",
        "print(f\"Average ROUGE-2 score: {average_rouge_2}\")\n",
        "print(f\"Average ROUGE-L score: {average_rouge_L}\")\n",
        "print(f\"Average BERT Precision: {average_bert_precision}\")\n",
        "print(f\"Average BERT Recall: {average_bert_recall}\")\n",
        "print(f\"Average BERT F1: {average_bert_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
